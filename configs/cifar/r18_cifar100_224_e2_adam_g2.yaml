NUM_GPUS: 2
NUM_NODES: 1
RANK_ID: 0
DIST_BACKEND: "nccl"
RNG_SEED: 1
OUTPUT_DIR: 'outputs/cifar/r18_cifar100_224_e2_adam_g2'
TRAIN:
  LOG_STEP: 10
  GRADIENT_ACCUMULATE_STEP: 1
  MAX_EPOCH: 2
  SAVE_EPOCH: 1
  EVAL_EPOCH: 1
  RESUME: False
  USE_TENSORBOARD: True
  HYBRID_PRECISION: True
SIMILARITY:
  LABELS_PER_BATCH: 8
  SAMPLES_PER_LABEL: 8
  MARGIN: 0.2
  P: 2.0
  MINING: "batch_all"
DATASET:
  NAME: 'PKDataset'
  TRAIN_ROOT: 'data/cifar/train'
  TEST_ROOT: 'data/cifar/test'
TRANSFORM:
  TRAIN_METHODS: ('Resize', 'Normalize', 'ToTensor')
  TEST_METHODS: ('Resize', 'Normalize', 'ToTensor')
  TRAIN_RESIZE: ((224, 224), 1, 0, 1.0)
  TEST_RESIZE: ((224, 224), 1, 0, 1.0)
  NORMALIZE: ((0.445, 0.445, 0.445), (0.225, 0.225, 0.225), 255.0, 1.0)
  TO_TENSOR: 1.0
DATALOADER:
  TRAIN_BATCH_SIZE: 64
  TEST_BATCH_SIZE: 64
  NUM_WORKERS: 4
  RANDOM_SAMPLE: True
  PREFETCHER: True
MODEL:
  HEAD:
    NUM_CLASSES: 100
  RECOGNIZER:
    NAME: 'resnet18'
  CRITERION:
    NAME: 'TripletMarginLoss'
OPTIMIZER:
  NAME: 'ADAM'
  LR: 0.0001
  MOMENTUM: 0.9
  WEIGHT_DECAY:
    DECAY: 4e-5
    NO_BIAS: True
    NO_NORM: True
LR_SCHEDULER:
  NAME: 'CosineAnnealingLR'
  IS_WARMUP: False
  GAMMA: 0.5
  COSINE_ANNEALING_LR:
    MINIMAL_LR: 1e-5
